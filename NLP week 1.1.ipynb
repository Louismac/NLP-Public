{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Tutorial. NLP Week 1.1\n",
    "\n",
    "Notebooks a separated up into cells. Each cell can contain text in Markdown form (like this one), or Python code (See below)\n",
    "\n",
    "Each cell can be run in turn using “Shift + Enter” \n",
    "\n",
    "The output of the final line of code will be displayed underneath. Here we store a string in the variable \"a\" and then use the .upper() function to convert it to uppercase. As this method is the final line in the cell, and returns a value (new upper cased string), it is displayed underneath, along with any explicit print statements in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"this should be shouted\"\n",
    "print(\"what did you say?\")\n",
    "a.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you store things in variables, the state remains throughout the document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still has the value from before\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"As I've matured, I've changed my views on speaker volume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#has the new value\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell states and shortcuts\n",
    "\n",
    "There are two main states to be in \"Command mode\" (with the blue highlights) and \"Edit mode\" (with the green highlights). \n",
    "\n",
    "Broadly in Command mode we are editting the whole notebook, and in edit mode we are editting the insides of the cells\n",
    "\n",
    "Popular shortcuts in Command Mode are \n",
    "\n",
    "- A = add cell above\n",
    "- B = add cell below \n",
    "- X = delete cell\n",
    "- M = set cell to mark down \n",
    "- Y = set cell to code\n",
    "\n",
    "First lets check which version of Python the notebook is using. We can evaluate anyting that we would in the terminal in a notebook by putting a \"!\" first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two ways to store data\n",
    "\n",
    "Before we look at our first text datasets, lets look at two different ways to store collections of objects in Python. \n",
    "\n",
    "#### Arrays \n",
    "Arrays are sequential lists. This means that the order matters. Each item is stored in order, and accessed by providing a index. Indexes start at 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Arrays \n",
    "a = [1,4,9,16,25]\n",
    "length = len(a)\n",
    "print(\"the array is \" + str(length) + \" elements long\")\n",
    "print(\"the second element is \" + str(a[1]))\n",
    "print(\"the final element is \" + str(a[length - 1]))\n",
    "#Changing values \n",
    "a[1] = 100\n",
    "print(\"the second element is now \" + str(a[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries\n",
    "Dictionaries are lists that have store pairs of _keys_ and _values_. The _key_ is almost always a string, and the _value_ can be any Python object. A particular _key_ can only appear once per dictionary, and there is no sense of order in the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries\n",
    "a = {}\n",
    "a[\"name\"] = \"Louis\"\n",
    "a[\"cat\"] = \"Diana\"\n",
    "print(a[\"name\"]+\"'s cat is called \" + a[\"cat\"])\n",
    "#Storing a new value with an existing key replaces the old one\n",
    "a[\"name\"] = \"Sophie\"\n",
    "print(a[\"name\"]+\"'s cat is also called \" + a[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing \n",
    "\n",
    "We are going to learn how to download and import a new Python library, load in a dataset of text and then learn something about the document by counting the occurences of each word. \n",
    "\n",
    "Python packages are small bundles of code you can download and use in your projects. If you want to use a particular package in a notebook, you must first import it. Below we are importing the Counter object from the collections package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Counter \n",
    "\n",
    "Below we have a quote from Joan Rivers. This will be our first very small corpus. We then pass this quote (as a single string object) to the Counter and display the results. This result is a **Dictionary**, where the _keys_ are the items being counted, and the _values_ are the number of times they each appeared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joan = \"Listen . I wish I could tell you it gets better . But it doesn't get better . You get better .\"\n",
    "Counter(joan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this do what we expected? Does the result provide us with any useful insights? \n",
    "\n",
    "Perhaps what would be more useful would be if we first split the string into words, before passing it to the Counter object. The ```split()``` method is called on a string and separates it into smaller strings based on a **delimiter**. In this case, we have told it to separate between every space (\" \"), and what we get back is an **array** of strings. We then pass this to the Counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joan_split = joan.split(\" \")\n",
    "print(joan_split)\n",
    "Counter(joan_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better. \n",
    "\n",
    "So what does this tell us? We can already see some questions are raised. What are the most common words? Do you care that there are 4 full stops? Are \"You\" and \"you\" different words, are should we count them as the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching a new package\n",
    "\n",
    "Next we're going to load a new library using pip, a package manager for Python. This will download the package (nlpia), and any other packages that it needs that you don't already have, from the internet and store it in a genreal repo on your machine. Next time it can just load the package from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nlpia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a dataset \n",
    "\n",
    "Here we import to the get_data method from the nlpia.loaders class and then use it to import the \"cats_and_dogs\" dataset. It comes with the nlpia package so doesnt need to download anything extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpia.loaders import get_data\n",
    "cats = get_data(\"cats_and_dogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra tasks \n",
    "\n",
    "Now we're going to spend the rest of the lab exploring this dataset and getting to know some ways of manipulating strings and lists that will help us\n",
    "\n",
    "First lets just look at the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see its a list of strings. Specifically, its a type of list called an array, that belongs to a library called numpy that we will be using alot. You can find the documentation [here](https://numpy.org/doc/)\n",
    "\n",
    "### Question 1\n",
    "How many sentences are there in the dataset. Use the cell below and using the numpy documentation, see if you can find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Its also super useful to be able to access different items, or groups of items in an array. Using the documentation, ([this guide is especially useful](https://numpy.org/doc/stable/reference/arrays.indexing.html), and maybe abit of web searching, can you find these parts of the cats dataset. You should be able to do each one with only one line of code!\n",
    "1. The 30th sentence\n",
    "2. The last sentence \n",
    "3. The 10th - 20th sentences \n",
    "4. The first, 23rd, and 45th sentences \n",
    "5. The last 10 sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "We want to find out how many occurences of each word are in the whole corpus (every sentence combined), like we did with the Joan Rivers quote above. If you use the Counter object on the cats array directly it will not work, it will count the occurences of each sentence **not** each word. This is not very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(cats)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What we need to do is \n",
    "\n",
    "1. Combine the array of strings into one long string\n",
    "2. Split that back up based on spaces \n",
    "3. Put that array into a Counter object \n",
    "\n",
    "Use the Numpy and [Python docs](https://docs.python.org/2/library/stdtypes.html#string-methods) to see if you can do the above change to the cats dataset so that you can put it in a Counter object and get back the occurences of each word in the whole dataset.\n",
    "\n",
    "Hint:The string methods ```join()``` and ```split()``` are your friends here.\n",
    "\n",
    "#### Bonus\n",
    "1. Can you change the corpus so uppercase/capitalised and lower/non-capitalised words are counted as the same word?\n",
    "2. Can you sort the output of the counter? What are the top 10 words? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even Bonus-er\n",
    "The nlpia library has a bunch of other text datasets that it comes with. Check out the [Github page](https://github.com/totalgood/nlpia/tree/master/src/nlpia/data) and see if you can work out how to load any thoer datasets in. If you can, try and explore them using the skills you've learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
