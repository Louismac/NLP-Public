{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_S_E1D-8MAY"
   },
   "source": [
    "# Images as Sequences\n",
    "\n",
    "Although typically 2D, we can treat images as in a similar way to text. \n",
    "\n",
    "We can treat the RGB values (e.g. `243-78-23`) as tokens and flatten the image into 1 long list. In this way, we can model and generate images using the same techniques we might use for generating text, however, instead of the tokens being words or characters, they are pixel colour values!\n",
    "\n",
    "In this notebook, you can generate new images from a directory of images using either **Markov Models** or **LSTMS**. \n",
    "\n",
    "Your choice of dataset, amount of history you look at when predicting the next values and other model parameters will effect your outcomes\n",
    "\n",
    "### MAKE SURE YOU ARE RUNNING A GPU\n",
    "\n",
    "\n",
    "# Markov Model \n",
    "\n",
    "The code below uses [William Anderson's](https://magenta.as/using-machine-learning-to-make-art-84df7d3bb911) Markov Model code to generate images based on a dataset. You can check out the blog post he wrote to find out more abou the process and his exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCmmA1B5uIq-",
    "outputId": "556bd379-dc1d-43c4-84fa-1b9c0be748e5"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/william-index/markov-fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqDaB8G2uMNv",
    "outputId": "e330cb50-b192-4e11-959a-d130598a10fa"
   },
   "outputs": [],
   "source": [
    "%cd /content/markov-fun/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdJtkcJx0R3c"
   },
   "outputs": [],
   "source": [
    "import argparse, os, pickle\n",
    "from PIL import Image\n",
    "from Trainer import DataTrainer, ImageSequencer\n",
    "from Stepper import Stepper\n",
    "\n",
    "\n",
    "def generate_markov():\n",
    "  trainer = DataTrainer()\n",
    "  stepper = Stepper()\n",
    "  img_sequencer = ImageSequencer()\n",
    "\n",
    "  should_pickle = True\n",
    "  pickle_file_name = \"{width}-{height}-{norder}.pickle\".format(width=im_width, height=im_height, norder=norder)\n",
    "  pickled_data = {}\n",
    "  preexisting_pickle = False\n",
    "\n",
    "  #  checks for and loads pickle\n",
    "  if should_pickle:\n",
    "      print('checking for pickle..')\n",
    "\n",
    "      has_pickle = os.path.isfile(directory + pickle_file_name)\n",
    "      if has_pickle:\n",
    "          print('Loading Pickled Data...')\n",
    "          with open(directory + pickle_file_name, 'rb') as pickle_file:\n",
    "              pickled_data = pickle.load(pickle_file)\n",
    "\n",
    "  if pickled_data:\n",
    "      print('Pickled data set')\n",
    "      trained_data = pickled_data\n",
    "      preexisting_pickle = True\n",
    "  else:\n",
    "      print('Training based on image set...')\n",
    "      image_set = []\n",
    "      for fn in os.listdir(directory):\n",
    "          if fn[0] != '.' and fn[-7:] !=\".pickle\":\n",
    "              image_set.append(directory + fn)\n",
    "\n",
    "      concat_text = \"\"\n",
    "      for image in image_set:\n",
    "          image = Image.open(image)\n",
    "          image_as_text = img_sequencer.sequence_image_to_text(image)\n",
    "          concat_text = concat_text + ' ' + image_as_text\n",
    "\n",
    "      concat_text.strip()\n",
    "\n",
    "      trained_data = trainer.train_text_data(\n",
    "              raw_text = concat_text,\n",
    "              order = norder,\n",
    "              )\n",
    "\n",
    "  # saves pickeled data\n",
    "  if should_pickle and preexisting_pickle == False:\n",
    "      print('Pickling data for later use...')\n",
    "      with open(directory + pickle_file_name, 'wb+') as pickle_file:\n",
    "          pickle.dump(trained_data, pickle_file)\n",
    "          pickle_file.close()\n",
    "\n",
    "  print('Stepping Image Sequence...')\n",
    "  gen_seq = stepper.new_set_length_sequence(\n",
    "          model = trained_data,\n",
    "          steps = im_width * im_height\n",
    "          )\n",
    "\n",
    "  print('Generating Image...')\n",
    "  image = img_sequencer.convert_text_to_image(gen_seq, im_width, im_height)\n",
    "  image.save(\"data/processed/images/sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62SYpuqdPZIH"
   },
   "source": [
    "# Upload your images\n",
    "\n",
    "Probably the easiest way to do this is to mount your Google Drive. \n",
    "\n",
    "You will get results if all your images are cropped to square. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgBcyPIQPY47"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJM6wvMl9SEQ"
   },
   "source": [
    "# Parameters\n",
    "\n",
    "There are 3 main parameters to play with when generating images \n",
    "\n",
    "1. The dataset. Point the model to a directory containing image files (e.g. one you have uploaded to your mounted Google Drive). The default one is the **Bauhaus** dataset used by William Anderson (choose your own!)\n",
    "\n",
    "2. Size of image to be generated \n",
    "\n",
    "3. Order of the Markov chain. This determines how many previous pixels we look at when guessing the next one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pELnUZuu9N8f"
   },
   "outputs": [],
   "source": [
    "directory = \"data/training/curated/bauhaus/\"\n",
    "im_width, im_height = 128,128\n",
    "norder = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifpdQTiW9t07"
   },
   "source": [
    "# Generate!\n",
    "Running this code repeatedly will yield different results as the seed is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0A5KVPUduPPL",
    "outputId": "29408acb-5d0f-477b-bca0-f827c1d6c17e"
   },
   "outputs": [],
   "source": [
    "generate_markov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaMFz9dY91S_"
   },
   "source": [
    "# View Image\n",
    "\n",
    "If you want to **download** your image, you can use the Colab File Explorer on the left <---\n",
    "\n",
    "The path is given below, you can just select any file and click **Download**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "Gh1a5QvWuc-F",
    "outputId": "d8334105-7a95-4279-827c-39d5b8c0a22d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = Image.open(\"data/processed/images/sample.png\")\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNzY9F3n_Fgf"
   },
   "source": [
    "# LSTMS\n",
    "\n",
    "Now we're going to compare the output of the Markov Model to an LSTM. This code is editted from the [Keras Char level LSTM example](https://keras.io/examples/generative/lstm_character_level_text_generation/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOzq2DRIBX8J"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74oWts92BeJ5"
   },
   "source": [
    "# Make dataset\n",
    "\n",
    "Again we can pick\n",
    "\n",
    "1. Dataset of images\n",
    "\n",
    "2. Amount of history to look back on (`norder`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1A9BbvuzSlg",
    "outputId": "3d579fca-fb0b-4261-aed2-4ee1bf4b54bb"
   },
   "outputs": [],
   "source": [
    "directory = \"data/training/curated/bauhaus/\"\n",
    "im_width, im_height = 128,128\n",
    "norder = 250\n",
    "\n",
    "img_sequencer = ImageSequencer()\n",
    "image_set = []\n",
    "for fn in os.listdir(directory):\n",
    "          if fn[0] != '.' and fn[-7:] !=\".pickle\":\n",
    "              image_set.append(directory + fn)\n",
    "concat_text = \"\"\n",
    "for image in image_set:\n",
    "    image = Image.open(image)\n",
    "    image_as_text = img_sequencer.sequence_image_to_text(image)\n",
    "    concat_text = concat_text + ' ' + image_as_text\n",
    "\n",
    "concat_text.strip()\n",
    "\n",
    "text = concat_text.split()\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 250\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DotAqdwfBjDx"
   },
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybW6OSvrz7KK"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DN2SGlNLBlLC"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePt_QGYC-BE3",
    "outputId": "397abf0a-c344-4d14-8ce5-7d22cee123d1"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 512\n",
    "for epoch in range(epochs):\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xw12ieL2z_dU"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate(diversity = 1.0):\n",
    "    # helper function to generate new pixel sequence\n",
    "    print()\n",
    "    print(\"Generating text after epoch: %d\" % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    print(\"...Diversity:\", diversity)\n",
    "\n",
    "    generated = \"\"\n",
    "    sentence = text[start_index : start_index + maxlen]\n",
    "    print('...Generating with seed: \"' + str(sentence) + '\"')\n",
    "\n",
    "    for i in range(im_width * im_height):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.0\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        sentence[:-1]=sentence[1:]\n",
    "        sentence[-1]=next_char\n",
    "        generated = generated + \" \"  + next_char\n",
    "\n",
    "    print(\"...Generated: \", generated)\n",
    "    print()\n",
    "    image = img_sequencer.convert_text_to_image(generated, im_width, im_height)\n",
    "    image.save(\"data/processed/images/sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "347me0Xo-FTI"
   },
   "source": [
    "#Generate a new image\n",
    "\n",
    "Warning, making bigger images (e.g. 128 x 128) make take a while (~ 5mins)\n",
    "\n",
    "Pick a `diversity` values between 0.2 and 1.5, this determines how true to the original dataset the generation is. High diversity = more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HD6uvCKn5PpZ",
    "outputId": "a73a041a-c238-46bc-c55d-5896183049b8"
   },
   "outputs": [],
   "source": [
    "im_width = 32\n",
    "im_height = 32\n",
    "diversity = 1.0\n",
    "generate(diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8nZCQN5-kFD"
   },
   "source": [
    "# View image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "pqhARTw-6Lih",
    "outputId": "bf2a5499-7561-4973-e4f8-6180a5bec03a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = Image.open(\"data/processed/images/sample.png\")\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Images as Sequences",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
