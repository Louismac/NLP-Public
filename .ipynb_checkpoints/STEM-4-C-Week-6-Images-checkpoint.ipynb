{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEM for Creatives Week 6  - Images\n",
    "\n",
    "This week we are going to look at how images are represented on computers, and how we can use some basic techiques to manuipluate them, and start to analyse them. \n",
    "\n",
    "### Pixels\n",
    "\n",
    "As we saw with audio, when we break media down on computers, they are just multi-dimensional arrays. Whilst audio is often 1-dimensional (or more for multi-channel audio), images have more components to them. \n",
    "\n",
    "Whilst digital audio is made up of **samples**, digital images are made up of **pixels**. When we are dealing with black and white images (often known as **grayscale**), each image is a **2D array**, which each dimension relating to \n",
    "\n",
    "- row (height)\n",
    "- column (width)\n",
    "\n",
    "Each item in this array represents a pixel and its number tells us where on the scale of black (low) to white (high) it is. We can use different types of numbers to represent ecah pixel but often the scale is 0 - 255.\n",
    "\n",
    "### PIL (Python Imaging Library)\n",
    "\n",
    "We use PIL to import and display images, and then turn them into **NumPy** arrays. And we know how to do things with them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!git clone https://github.com/Louismac/NLP-Public\n",
    "%cd NLP-Public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#This is actually a colour image, so we make it grayscale to begin with (convert('L'))\n",
    "im = np.array(Image.open('images/robot-enstein.jpg').convert('L'))\n",
    "Image.fromarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How big is it?\n",
    "h = im.shape[0]\n",
    "w = im.shape[1]\n",
    "print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at pixels\n",
    "#Gives us the grayscale of a particular pixel \n",
    "print(im[12,45])\n",
    "#Pixel in the middle\n",
    "mid_y = int(h/2)\n",
    "mid_x = int(w/2)\n",
    "print(im[mid_y,mid_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colour (RGB)\n",
    "\n",
    "Sure grayscale is good, but have you tried colour? In the RGB representation an image is made up of three channels\n",
    "\n",
    "- **R**ed\n",
    "- **G**reen \n",
    "- **B**lue \n",
    "\n",
    "So in a way its actually like 3 images, that combine together to make the full colour output. We can get all colours from combinations of these three base colours.\n",
    "\n",
    "### Colour Channels\n",
    "\n",
    "So how does effect our NumPy array? We end up with a **3D array**, whose dimensions map to \n",
    "\n",
    "- row (height)\n",
    "- column (width)\n",
    "- color (channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array(Image.open('images/robot-enstein.jpg'))\n",
    "Image.fromarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the size and number of channels\n",
    "h = im.shape[0]\n",
    "w = im.shape[1]\n",
    "c = im.shape[2]\n",
    "print(w, h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at pixels\n",
    "#Gives us the RGB of a particular pixel -> We get three values for each one!\n",
    "print(im[12,45])\n",
    "#Pixel in the middle\n",
    "print(im[mid_y,mid_x-60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Pixel Values\n",
    "\n",
    "As well as looking at pixel values, we can also set them to new things. We can do this by just changing the values in the arrays, just like we did with audio files. \n",
    "\n",
    "When we change the file, like we did with the audio, we first make a copy. This way the original image file stays unaltered so we can use it again  \n",
    "\n",
    "```\n",
    "new_image = im.copy()\n",
    "```\n",
    "\n",
    "#### Tuples\n",
    "\n",
    "We can do this to single pixels, or groups of pixels. Each pixel is actually represented as a **tuple**. Tuples are single objects that hold mutiple values and are a **collection which is ordered and unchangeable**. This means we can access the items inside with indexes (because its ordered), but we cant change them (because they're unchangeable).\n",
    "\n",
    "Tuples are written, and created, with **round brackets**\n",
    "\n",
    "```\n",
    "a = (1,2,3,4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the middle pixel to full red (RGB). Look reeeeal closely.\n",
    "new_image = im.copy()\n",
    "new_image[mid_y,mid_x] = (255,0,0)\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting \n",
    "\n",
    "We've seen in most cases that we do operations with arrays, they need to be the same size in all dimensions. For example\n",
    "\n",
    "```\n",
    "a = [1,2,3,5,6]\n",
    "b = [4,5,6,7,8]\n",
    "c = a + b\n",
    "```\n",
    "\n",
    "Adds the two arrays together **element-wise**. This means \n",
    "\n",
    "```\n",
    "c[0] = a[0] + b[0]\n",
    "c[1] = a[1] + b[1]\n",
    "...\n",
    "c[i] = a[i] + b[i]\n",
    "```\n",
    "\n",
    "This also works in more dimensions \n",
    "\n",
    "```\n",
    "a = [[1,2,3],[4,5,6]]\n",
    "b = [[4,5,6],[7,8,9]]\n",
    "c = a + b\n",
    "```\n",
    "\n",
    "Adds the two arrays together **element-wise** again\n",
    "\n",
    "```\n",
    "c[0,0] = a[0,0] + b[0,0]\n",
    "c[1,0] = a[1,0] + b[1,0]\n",
    "...\n",
    "c[i,j] = a[i,j] + b[i,j]\n",
    "```\n",
    "\n",
    "However, there are circumstances where we can have two things that are have different dimensions and NumPy will use **broadcasting** to work out what to do. We've seen this before with single values \n",
    "\n",
    "```\n",
    "a = [1,2,3,4,5]\n",
    "b = 2\n",
    "c = a * b\n",
    "```\n",
    "\n",
    "We multiply every element in `a` by `b`\n",
    "\n",
    "```\n",
    "c[0] = a[0] * b\n",
    "c[1] = a[1] * b\n",
    "...\n",
    "c[i] = a[i] * b\n",
    "```\n",
    "\n",
    "This can also work with more dimensions, for example this:\n",
    "\n",
    "```\n",
    "a = [[1,2,3],[4,5,6]]\n",
    "b = [1,2,3]\n",
    "c = a + b\n",
    "```\n",
    "\n",
    "Works because a set of arrays is said to be broadcastable if **one** of the following is true\n",
    "\n",
    " - Arrays have exactly the same shape.\n",
    "\n",
    " - Arrays have the same number of dimensions and the length of each dimension is either the same or 1.\n",
    "\n",
    " - Array having too few dimensions can have its shape prepended with a dimension of length 1, so that the above stated property is true. In this case, the smaller array is **broadcasted** to match the dimensions of the larger array\n",
    "\n",
    "Because the shapes are `(2, 3)` and `(3)`, then you can prepend one dimension onto `b` (making `(1, 3)`) and the rules hold true. We would then do the arithmetic element-wise by row \n",
    "\n",
    "```\n",
    "c[0,0] = a[0,0] + b[0]\n",
    "c[1,0] = a[2,0] + b[1]\n",
    "c[2,0] = a[3,0] + b[2]\n",
    "c[1,0] = a[1,0] + b[0]\n",
    "...\n",
    "c[i,j] = a[i,j] + b[j]\n",
    "```\n",
    "\n",
    "However\n",
    "\n",
    "```\n",
    "a = [[1,2,3],[4,5,6]]\n",
    "b = [1,2]\n",
    "c = a + b\n",
    "```\n",
    "\n",
    "**Doesn't work** because the shapes are `(2, 3)` and `(2)`, and theres no way of prepending dimensions of 1 `b` so that the rules hold true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image[0:100,0:100].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set 100 x 100 square in top left to green (RGB)\n",
    "new_image = im.copy()\n",
    "new_image[0:100,0:100] = (0,255,0)\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Colours\n",
    "\n",
    "We can also use **broadcasting** to split out individual colours by setting all other channels to 0. \n",
    "\n",
    "We use the `:` to select all rows and columns, then use a **array of indexes** to specify which channels we want to set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all the pixels for (1,2) to zero (green and blue)\n",
    "new_image = im.copy()\n",
    "new_image[:, :, [1, 2]] = 0\n",
    "print(new_image[:, :, [1, 2]].shape)\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all the pixels for (0,2) to zero (red and blue)\n",
    "new_image = im.copy()\n",
    "new_image[:, :, [0, 2]] = 0\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all the pixels for (0,1) to zero (red and green)\n",
    "new_image = im.copy()\n",
    "new_image[:, :, [0, 1]] = 0\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming\n",
    "\n",
    "We can cut sections out of our array to trim the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trim a square out of the centre\n",
    "cut = 100\n",
    "new_image = im[mid_y-cut:mid_y+cut,mid_x-cut:mid_x+cut]\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the blue values of the centre square to 0, leaving yellow!\n",
    "cut = 100\n",
    "new_image = im.copy()\n",
    "new_image[mid_y-cut:mid_y+cut,mid_x-cut:mid_x+cut,2] = 0\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy paste\n",
    "\n",
    "You can also cut out sections and place them back together in different places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = im.copy()\n",
    "face = im[30:100,150:230]\n",
    "fh = face.shape[0]\n",
    "fw = face.shape[1]\n",
    "#Use the size of the face when indexing to make sure its the right size\n",
    "new_image[:fh,:fw] = face\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tile face\n",
    "new_image = im.copy()\n",
    "square = 80\n",
    "for i in [-1,0,1]:\n",
    "    for j in [-1,0,1]:\n",
    "        y = int(mid_y + (square * i) - (fh/2))\n",
    "        x = int(mid_x + (square * j) - (fw/2))\n",
    "        new_image[y:y+fh, x:x+fw] = face\n",
    "Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending\n",
    "\n",
    "We can multiply the sections by fractions to create an transparency blending effect. Its important to remember here that we have to **fade both images**. Otherwise, when we add them together, some values might go over 255 (which is the max). In which case bad things happen. \n",
    "\n",
    "Also, what happens when you **subtract** instead of add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = np.array(Image.open('images/sunset.jpg'))\n",
    "new_image = im2.copy()\n",
    "#Fade the sunset 70%\n",
    "new_image = new_image * 0.7\n",
    "face = im[30:100,150:230].copy()\n",
    "#Fade the sunset 30%\n",
    "face = face * 0.3\n",
    "fh = face.shape[0]\n",
    "fw = face.shape[1]\n",
    "y = 70\n",
    "x = 170\n",
    "new_image[y:y+fh,x:x+fw] = new_image[y:y+fh:,x:x+fw] + face\n",
    "#Because we've done multiplying by decimals, we have to make sure the pixels are ints again\n",
    "Image.fromarray(new_image.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with multiple images \n",
    "\n",
    "We can also average loads pictures together to find a mean value image! To do this we're going to use a Python function that will do a `recursive walk` into a file system. We can do this to get every image in a folder!\n",
    "\n",
    "When all the images are the same size, this is easy\n",
    "\n",
    "### The `os` Package\n",
    "\n",
    "`os` is a Python package provides a way of using operating system dependent functionality.\n",
    "\n",
    "The functions that the OS module provides allows you to interface with the underlying operating system that Python is running on – be that Windows, Mac or Linux.\n",
    "\n",
    "We use two key functions in the code below\n",
    "\n",
    "1. `os.walk`\n",
    "\n",
    "    We provide a root folder, and this does a `walk` through it (and all its subfolders) and returns all of the files it finds. First `for loop` iterates over every folder, and the inner `for loop` iterates over all the files in that folder. \n",
    "    \n",
    "    \n",
    "2. `os.path.join`\n",
    "\n",
    "    This makes us a file path by joining together two strings, and does so in the correct manner depending on what operating systems we are running on. If oyu want code that will run many places, this is the safest thing to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "faces = []\n",
    "crop = 256\n",
    "#Go through all the files in the faces folder\n",
    "for root, dirs, files in os.walk(\"images/faces\", topdown=False):\n",
    "    for name in files:\n",
    "        if \".png\" in name:\n",
    "            f = os.path.join(root, name)\n",
    "            im = np.array(Image.open(f))\n",
    "            faces = faces + [im]\n",
    "faces = np.array(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(faces[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging \n",
    "\n",
    "We now have a **4D array**, which is to say an array of images, each having 3D. \n",
    "\n",
    "To get the average of all the pictures, we average over the first dimension (images), to get back a **3D array** which is the average of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average face!\n",
    "print(faces.shape)\n",
    "mean_face = np.mean(faces,(0)).astype(np.uint8)\n",
    "print(mean_face.shape)\n",
    "Image.fromarray(mean_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with different sized images \n",
    "\n",
    "The above works because all the images are the same size. However, when they are different sizes we gotta do some cropping\n",
    "\n",
    "1. Do a first pass where we find the smallest width and height \n",
    "2. Do a second pass where load the image and centre-crop to the smallest size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find the smallest image\n",
    "cats = []\n",
    "#Start with infinity (anything will be smaller than this)\n",
    "smallest = [np.Inf, np.Inf]\n",
    "#Go through all the files in the cat folder\n",
    "for root, dirs, files in os.walk(\"images/cats\", topdown=False):\n",
    "    for name in files:\n",
    "        if \".jpg\" in name:\n",
    "            f = os.path.join(root, name)\n",
    "            im = np.array(Image.open(f))\n",
    "            #Update min height\n",
    "            if im.shape[0] < smallest[0]:\n",
    "                smallest[0] = im.shape[0]\n",
    "            #Update min width\n",
    "            if im.shape[1] < smallest[1]:\n",
    "                smallest[1] = im.shape[1]\n",
    "\n",
    "#Then crop all to the same size             \n",
    "crop_h = int(smallest[0]/2)\n",
    "crop_w = int(smallest[1]/2)\n",
    "#Go through all the files in the cat folder\n",
    "for root, dirs, files in os.walk(\"images/cats\", topdown=False):\n",
    "    for name in files:\n",
    "        if not \".DS_Store\" in name:\n",
    "            f = os.path.join(root, name)\n",
    "            im = np.array(Image.open(f))\n",
    "            #Centre crop to same size\n",
    "            mid_y = int(im.shape[0]/2)\n",
    "            mid_x = int(im.shape[1]/2)\n",
    "            im = im[mid_y-crop_h:mid_y+crop_h, mid_x-crop_w:mid_x+crop_w]\n",
    "            cats = cats + [im]\n",
    "cats = np.array(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average cat!\n",
    "Image.fromarray(np.mean(cats,(0)).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV\n",
    "\n",
    "As we did with audio and `librosa` I'm going to introduce you to the most popular library for getting information from images, its called [OpenCV](https://opencv.org/). \n",
    "\n",
    "**CV** for **Computer Vision**. \n",
    "\n",
    "You can do a lot of things we've done above in **OpenCV**, as well as a bunch of more complicated things! \n",
    "\n",
    "Again, like audio, images in their raw form (just pixels) are not super useful using as is in data science tasks, so we often extract features first. \n",
    "\n",
    "We could teach a whole unit on computer vision! OpenCV has a bunch of [tutorials](https://docs.opencv.org/4.5.0/d6/d00/tutorial_py_root.html) you can check out if you want to go deeper into the theory. \n",
    "\n",
    "### Aligning faces \n",
    "\n",
    "As an example, and also as a refresher on some basic **trigonometry** we're going to look at how to **align faces** using OpenCV. This task is broadly based on [Data Hackers](http://datahacker.rs/opencv-for-hackers/) tutorials, which are great and a good place to start digging deeper. \n",
    "\n",
    "We'll learn how to \n",
    "\n",
    "- Find facial landmarks \n",
    "- Use openCV to mark images \n",
    "- Use some trigonometry to get the correction angle for the face \n",
    "- Rotate the image to align the face\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python\n",
    "!pip install ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find the face\n",
    "face_cascade=cv2.CascadeClassifier(\"data/haarcascade_frontalface_default.xml\")\n",
    "eye_cascade=cv2.CascadeClassifier(\"data/haarcascade_eye.xml\")\n",
    "#Here is a picture of Kimberly Bryant, founder of Black Girls Code\n",
    "img = cv2.imread('images/kb2.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Converting the image into grayscale\n",
    "gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Creating variable faces\n",
    "faces= face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "# Defining and drawing the rectangle around the face\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(img, (x,y) ,(x+w, y+h), (0,255,0), 3)\n",
    "ipyplot.plot_images([img], img_width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the angle between the eyes\n",
    "\n",
    "Here we find the eyes and draw the line that connects them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gray=gray[y:(y+h), x:(x+w)]\n",
    "roi_color=img[y:(y+h), x:(x+w)]\n",
    "# Creating variable eyes\n",
    "eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 4)\n",
    "index=0\n",
    "# Creating for loop in order to divide one eye from another\n",
    "for (ex , ey,  ew,  eh) in eyes:\n",
    "    if index == 0:\n",
    "        #Save the eyes as TUPLES\n",
    "        eye_1 = (ex, ey, ew, eh)\n",
    "    elif index == 1:\n",
    "        eye_2 = (ex, ey, ew, eh)\n",
    "    # Drawing rectangles around the eyes\n",
    "    cv2.rectangle(roi_color, (ex,ey) ,(ex+ew, ey+eh), (0,0,255), 3)\n",
    "    index = index + 1\n",
    "\n",
    "if eye_1[0] < eye_2[0]:\n",
    "    left_eye = eye_1\n",
    "    right_eye = eye_2\n",
    "else:\n",
    "    left_eye = eye_2\n",
    "    right_eye = eye_1\n",
    "# Calculating coordinates of a central points of the rectangles\n",
    "left_eye_center = (int(left_eye[0] + (left_eye[2] / 2)), int(left_eye[1] + (left_eye[3] / 2)))\n",
    "left_eye_x = left_eye_center[0] \n",
    "left_eye_y = left_eye_center[1]\n",
    " \n",
    "right_eye_center = (int(right_eye[0] + (right_eye[2]/2)), int(right_eye[1] + (right_eye[3]/2)))\n",
    "right_eye_x = right_eye_center[0]\n",
    "right_eye_y = right_eye_center[1]\n",
    " \n",
    "cv2.circle(roi_color, left_eye_center, 5, (255, 0, 0) , -1)\n",
    "cv2.circle(roi_color, right_eye_center, 5, (255, 0, 0) , -1)\n",
    "cv2.line(roi_color,right_eye_center, left_eye_center,(0,200,200),1)\n",
    "if left_eye_y > right_eye_y:\n",
    "    A = (right_eye_x, left_eye_y)\n",
    "    # Integer -1 indicates that the image will rotate in the clockwise direction\n",
    "    direction = -1 \n",
    "else:\n",
    "    A = (left_eye_x, right_eye_y)\n",
    "    # Integer 1 indicates that image will rotate in the counter clockwise  \n",
    "    # direction\n",
    "    direction = 1 \n",
    "\n",
    "cv2.circle(roi_color, A, 5, (255, 0, 0) , -1)\n",
    " \n",
    "cv2.line(roi_color,right_eye_center, left_eye_center,(0,200,200),1)\n",
    "cv2.line(roi_color,left_eye_center, A,(0,200,200),1)\n",
    "cv2.line(roi_color,right_eye_center, A,(0,200,200),1)\n",
    "ipyplot.plot_images([img], img_width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigonometry Refresher \n",
    "\n",
    "Here we have a right angled triangle, it has 3 angles and 3 sides. If we know some of these things, then we are able to work out some of the **unknowns**. \n",
    "\n",
    "We name the sides of the triangle in the relation to the **right angle**. This is the angle which is 90 degrees in te corner. The three respective sides are \n",
    "\n",
    " - Adjacent \n",
    " - Opposite \n",
    " - Hypotenuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trig = cv2.imread('images/sohcahtoa.jpg')\n",
    "trig = cv2.cvtColor(trig, cv2.COLOR_BGR2RGB)\n",
    "ipyplot.plot_images([trig], img_width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Theta \n",
    "\n",
    "What we want to know is the angle in the corner of the triangle (shown by the greek symbol **Theta θ**). This will allow us to rotate the image back so that the face is aligned parallel in the image. \n",
    "\n",
    "If we look at the triangle we have made between the eyes, we know that have the values for the **adjacent** and **opposite** sides. Using the above rules, we can see that \n",
    "\n",
    "tan(θ) = opp/adj\n",
    "\n",
    "And by doing a bit of algebra, we do the opposite operation to tan to both sides to solve for θ. This is called **arctan**, and this exists for both sin (**arcsin**) and cos (**arccos**).\n",
    "\n",
    "θ = arctan(opp/adj)\n",
    "\n",
    "For all types of problems involving **right angled** triangles and you are looking to calculate **lengths** or **angles**, you can use the appropriate formula depending on what you know, and what you need to find out. \n",
    "\n",
    "For example, if you wanted to find out the length of the opposite side, and you knew the length of the hypotenuse (20) and the angle of theta (35):\n",
    "\n",
    "sin(θ) = opp/hyp\n",
    "\n",
    "sin(35) = opp/20\n",
    "\n",
    "20 * sin(35) = opp\n",
    "\n",
    "opp = 11.471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the \n",
    "adjacent = right_eye_x - left_eye_x\n",
    "opposite = right_eye_y - left_eye_y\n",
    "angle = np.arctan(opposite/adjacent)\n",
    "#Convert from radians into degrees\n",
    "angle = (angle * 180) / np.pi\n",
    "# Width and height of the image\n",
    "h, w = img.shape[:2]\n",
    "# Calculating a center point of the image\n",
    "# Integer division \"//\"\" ensures that we receive whole numbers\n",
    "center = (w // 2, h // 2)\n",
    "# Defining a matrix M and calling\n",
    "# cv2.getRotationMatrix2D method\n",
    "M = cv2.getRotationMatrix2D(center, (angle), 1.0)\n",
    "# Applying the rotation to our image using the\n",
    "# cv2.warpAffine method\n",
    "rotated = cv2.warpAffine(img, M, (w, h))\n",
    "ipyplot.plot_images([rotated], img_width=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
