{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg0_8zp-utP2"
   },
   "source": [
    "# Generating Audio with LSTM \n",
    "\n",
    "This notebookw will let you download a song from Youtube and model it with an **LSTM**\n",
    "\n",
    "This models the way each spectral frame follows another and can be used to generate new raw audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LWepcBCvDA0"
   },
   "source": [
    "## Install prerequisites and get code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "St4eugxz1VGF",
    "outputId": "d338abfc-5cc8-4d7e-9336-d492386b648d"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # less warnings ...\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ_Ufe-HuJQP",
    "outputId": "65e5df95-1b27-42bd-db7e-b97e05867582"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ual-cci/music_gen_interaction_RTML.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW7r6xROudFy",
    "outputId": "b97304cf-396f-402e-dba7-1f38dff6e2e3"
   },
   "outputs": [],
   "source": [
    "# python libraries\n",
    "!pip install Pillow numpy opencv-python PyWavelets tqdm slugify\n",
    "!pip install -U Flask\n",
    "!pip install lws==1.2.6\n",
    "!pip install tflearn\n",
    "!pip install librosa==0.7.2\n",
    "!pip install numba==0.48\n",
    "!pip install mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BJhlHuLBMru",
    "outputId": "d1fe976c-1402-48d4-918a-4249faf44261"
   },
   "outputs": [],
   "source": [
    "!pip install numba==0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAaR9elasbV7",
    "outputId": "3b6ce464-fdd8-4d56-b957-7fca225c60bf"
   },
   "outputs": [],
   "source": [
    "%cd /content/music_gen_interaction_RTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p04Rnk5_uw19"
   },
   "source": [
    "## Download a sample audio:\n",
    "\n",
    "Note: replace the url with whatever music video you want - or upload a file directly ... You can use the ffmpeg to convert it to wav later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcANvMFAtb8e",
    "outputId": "34cb461b-29b6-466a-efe8-67a09e9a510e"
   },
   "outputs": [],
   "source": [
    "# get a youtube downloader\n",
    "!sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl\n",
    "!sudo chmod a+rx /usr/local/bin/youtube-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQW9BUKnE13J"
   },
   "source": [
    "# Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_rvWlYC3rIN",
    "outputId": "dad485fe-459d-49e1-e64d-48c6eb915398"
   },
   "outputs": [],
   "source": [
    "\n",
    "%cd /content/music_gen_interaction_RTML/\n",
    "\n",
    "from unittest.mock import Mock, MagicMock\n",
    "args = MagicMock(name='method')\n",
    "sample_rate = 22050\n",
    "\n",
    "# keep the same settings as the model you used when training:\n",
    "args.lstm_layers = 3\n",
    "args.lstm_units = 128\n",
    "args.griffin_iterations = 60\n",
    "args.sample_rate = sample_rate\n",
    "args.sequence_length = 40\n",
    "args.async_loading = True\n",
    "args.amount_epochs = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifpajCHOT-wq"
   },
   "source": [
    "# Pick a new song from Youtube \n",
    "\n",
    "## Insert your own url below and train \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=4cIWu5m8UmA\"\n",
    "\n",
    "!youtube-dl -ci -f \"bestaudio[ext=m4a]\" $youtube_url -o 'youtube_audio.m4a'\n",
    "!ffmpeg -i 'youtube_audio.m4a' -ac 2 -f wav full.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will probably need to train for 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 150 # will take cca 4min\n",
    "number_of_epochs = 300 # will take cca 8min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "pyZ3BNJefXzn",
    "outputId": "d1f56258-1f35-45bf-d277-7a51a21efd2a"
   },
   "outputs": [],
   "source": [
    "# ----[keep the same bellow]-------------------------------------------------------------------\n",
    "!ffmpeg -ss 60 -i full.wav -t 60 -c copy sample.wav\n",
    "#\"\"\"\n",
    "!mkdir __music_samples\n",
    "!mkdir __music_samples/sample/\n",
    "!mv sample.wav __music_samples/sample/\n",
    "!mkdir __saved_models/\n",
    "\n",
    "# takes time!\n",
    "!python training_handler.py -target_file __music_samples/sample/ -amount_epochs $number_of_epochs -batch_size 512\n",
    "from IPython.display import clear_output \n",
    "clear_output()\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "l = glob.glob(\"__saved_models/*.wav\")\n",
    "a = l[np.random.randint(len(l))]\n",
    "i = glob.glob(\"__saved_models/*.png\")\n",
    "from IPython.display import Audio, Image\n",
    "display(Audio(a))\n",
    "display(Image(i[0]))\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bGNWTO-UJSC"
   },
   "source": [
    "# Generate\n",
    "\n",
    "As Vit mentioned in the lecture, we start from a place in the original audio track, then use the model to keep predicting new audio frames. \n",
    "\n",
    "Unfortunately, sometimes it can get stuck in a loop, or just stop generating interesting things so we can give it a kick by jumping to a new point in the song. \n",
    "\n",
    "Once we've switched, we keep using the model to generate new audio frames!\n",
    "\n",
    "Below, you can specify a sequence of lengths and changes to the generation process to create a new audio output. \n",
    "\n",
    "The `sequence` array stores these points. Each item in is an array that stores the **start position** and **segment length**. The default has three, but you can add in as many as you want and/or change the existing values. \n",
    "\n",
    "```\n",
    "sequence = [\n",
    "  [start1, length1],\n",
    "  [start2, length2],\n",
    "  [start3, length3],\n",
    "  etc....\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "The default code:\n",
    "\n",
    "* Starts generating 10% through the song and generates 200 frames \n",
    "\n",
    "* Moves to 60% through the song and generates 300 frames\n",
    "\n",
    "* Moves to 90% through the song and generates 150 frames\n",
    "\n",
    "**Try with your own!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YYrE8qKd1B1"
   },
   "outputs": [],
   "source": [
    "from server_handler import ServerHandler\n",
    "import settings\n",
    "\n",
    "my_settings = settings.Settings(args)\n",
    "my_settings.print_settings()\n",
    "\n",
    "generation_handler = ServerHandler(my_settings)\n",
    "\n",
    "# slightly experimental interpolation through the latents while generating ...\n",
    "\n",
    "generation_handler.change_impulse(0.2) # set to 20% sharp\n",
    "\n",
    "sequence = [\n",
    "  #Starts generating 10% through the song and generates 200 frames \n",
    "  [0.1, 200],\n",
    "  #Moves to 60% through the song and generates 300 frames\n",
    "  [0.6, 300],\n",
    "  #Moves to 90% through the song and generates 150 frames\n",
    "  [0.9, 150]            \n",
    "]\n",
    "\n",
    "output_audio = []\n",
    "\n",
    "for i in sequence:\n",
    "  position_in_the_song = i[0]\n",
    "  requested_length = i[1]\n",
    "  generation_handler.change_impulse_smoothly_start(position_in_the_song) # allow interpolation\n",
    "  audio, predict, reconstruct = generation_handler.generate_audio_sample(requested_length, interactive_i=position_in_the_song)\n",
    "  output_audio.append(audio)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H2iHKgMUmbD"
   },
   "source": [
    "# Play Audio\n",
    "\n",
    "If you want to download the audio, you can use the Colab File Explorer on the left <----. \n",
    "\n",
    "Find the file `generated_output_exp_concat.wav` and select **download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "EKOA8aGg24Zh",
    "outputId": "22fbe8be-01af-4a8e-961a-9872d26722de"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio, Image\n",
    "output_audio = np.concatenate(output_audio)\n",
    "\n",
    "out_name = 'generated_output_exp_concat.wav'\n",
    "librosa.output.write_wav(out_name, output_audio, sr=sample_rate)\n",
    "Audio(out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieFSgNbIUoPL"
   },
   "source": [
    "# Clean up if you are going to train a new model from a different youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gXtBaGR26oW"
   },
   "outputs": [],
   "source": [
    "# fast cleanup\n",
    "!mkdir unused\n",
    "!mv __music_samples unused/\n",
    "!mv __saved_models unused/\n",
    "!mv *.wav unused/\n",
    "!mv *.m4a unused/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM Audio Generation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
