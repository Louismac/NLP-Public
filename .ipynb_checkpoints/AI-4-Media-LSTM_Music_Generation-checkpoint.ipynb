{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg0_8zp-utP2"
   },
   "source": [
    "# Generating Audio with LSTM \n",
    "\n",
    "This notebookw will let you download a song from Youtube and model it with an **LSTM**\n",
    "\n",
    "This models the way each spectral frame follows another and can be used to generate new raw audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LWepcBCvDA0"
   },
   "source": [
    "## Install prerequisites and get code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "St4eugxz1VGF",
    "outputId": "d338abfc-5cc8-4d7e-9336-d492386b648d"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # less warnings ...\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ_Ufe-HuJQP",
    "outputId": "65e5df95-1b27-42bd-db7e-b97e05867582"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ual-cci/music_gen_interaction_RTML.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW7r6xROudFy",
    "outputId": "b97304cf-396f-402e-dba7-1f38dff6e2e3"
   },
   "outputs": [],
   "source": [
    "# python libraries\n",
    "!pip install Pillow numpy opencv-python PyWavelets tqdm slugify\n",
    "!pip install -U Flask\n",
    "!pip install lws==1.2.6\n",
    "!pip install tflearn\n",
    "!pip install librosa==0.7.2\n",
    "!pip install numba==0.48\n",
    "!pip install mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BJhlHuLBMru",
    "outputId": "d1fe976c-1402-48d4-918a-4249faf44261"
   },
   "outputs": [],
   "source": [
    "!pip install numba==0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAaR9elasbV7",
    "outputId": "3b6ce464-fdd8-4d56-b957-7fca225c60bf"
   },
   "outputs": [],
   "source": [
    "%cd /content/music_gen_interaction_RTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p04Rnk5_uw19"
   },
   "source": [
    "## Download a sample audio:\n",
    "\n",
    "Note: replace the url with whatever music video you want - or upload a file directly ... You can use the ffmpeg to convert it to wav later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcANvMFAtb8e",
    "outputId": "34cb461b-29b6-466a-efe8-67a09e9a510e"
   },
   "outputs": [],
   "source": [
    "# get a youtube downloader\n",
    "!sudo curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl\n",
    "!sudo chmod a+rx /usr/local/bin/youtube-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQW9BUKnE13J"
   },
   "source": [
    "# Pick a song from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_rvWlYC3rIN",
    "outputId": "dad485fe-459d-49e1-e64d-48c6eb915398"
   },
   "outputs": [],
   "source": [
    "\n",
    "%cd /content/music_gen_interaction_RTML/\n",
    "\n",
    "from unittest.mock import Mock, MagicMock\n",
    "args = MagicMock(name='method')\n",
    "sample_rate = 22050\n",
    "\n",
    "# keep the same settings as the model you used when training:\n",
    "args.lstm_layers = 3\n",
    "args.lstm_units = 128\n",
    "args.griffin_iterations = 60\n",
    "args.sample_rate = sample_rate\n",
    "args.sequence_length = 40\n",
    "args.async_loading = True\n",
    "args.amount_epochs = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifpajCHOT-wq"
   },
   "source": [
    "# Insert your own url below and train \n",
    "\n",
    "You will probably need to train for 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "pyZ3BNJefXzn",
    "outputId": "d1f56258-1f35-45bf-d277-7a51a21efd2a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4 Orbital - Halcyon\n",
    "!youtube-dl -ci -f \"bestaudio[ext=m4a]\" https://www.youtube.com/watch?v=3SwwljI-8JY -o 'youtube_audio.m4a'\n",
    "!ffmpeg -i 'youtube_audio.m4a' -ac 2 -f wav full.wav\n",
    "\n",
    "number_of_epochs = 300 # will take cca 8min\n",
    "number_of_epochs = 150 # will take cca 4min\n",
    "\n",
    "# ----[keep the same bellow]-------------------------------------------------------------------\n",
    "!ffmpeg -ss 60 -i full.wav -t 60 -c copy sample.wav\n",
    "#\"\"\"\n",
    "!mkdir __music_samples\n",
    "!mkdir __music_samples/sample/\n",
    "!mv sample.wav __music_samples/sample/\n",
    "!mkdir __saved_models/\n",
    "\n",
    "# takes time!\n",
    "!python training_handler.py -target_file __music_samples/sample/ -amount_epochs $number_of_epochs -batch_size 512\n",
    "from IPython.display import clear_output \n",
    "clear_output()\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "l = glob.glob(\"__saved_models/*.wav\")\n",
    "a = l[np.random.randint(len(l))]\n",
    "i = glob.glob(\"__saved_models/*.png\")\n",
    "from IPython.display import Audio, Image\n",
    "display(Audio(a))\n",
    "display(Image(i[0]))\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bGNWTO-UJSC"
   },
   "source": [
    "# Generate\n",
    "\n",
    "Experiment with different start points (`position_in_the_song`) and lengths (`requested_length`) to build up interesting sequences by jumping to different parts in the song\n",
    "\n",
    "The code below \n",
    "\n",
    "* Starts generating 10% through the song and generates 200 frames \n",
    "\n",
    "* Moves to 60% through the song and generates 300 frames\n",
    "\n",
    "* Moves to 90% through the song and generates 150 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YYrE8qKd1B1"
   },
   "outputs": [],
   "source": [
    "from server_handler import ServerHandler\n",
    "import settings\n",
    "\n",
    "my_settings = settings.Settings(args)\n",
    "my_settings.print_settings()\n",
    "\n",
    "generation_handler = ServerHandler(my_settings)\n",
    "\n",
    "# slightly experimental interpolation through the latents while generating ...\n",
    "\n",
    "generation_handler.change_impulse(0.2) # set to 20% sharp\n",
    "\n",
    "#Clip 1\n",
    "position_in_the_song = 0.1\n",
    "requested_length = 200\n",
    "\n",
    "generation_handler.change_impulse_smoothly_start(position_in_the_song) # allow interpolation\n",
    "audio_arr_exp1, t_predict, t_reconstruct = generation_handler.generate_audio_sample(requested_length, interactive_i=position_in_the_song)\n",
    "\n",
    "#Clip 2\n",
    "position_in_the_song = 0.6\n",
    "requested_length = 300\n",
    "\n",
    "generation_handler.change_impulse_smoothly_start(position_in_the_song)\n",
    "audio_arr_exp2, t_predict, t_reconstruct = generation_handler.generate_audio_sample(requested_length, interactive_i=position_in_the_song)\n",
    "\n",
    "#Clip 3\n",
    "position_in_the_song = 0.9\n",
    "requested_length = 150\n",
    "\n",
    "generation_handler.change_impulse_smoothly_start(position_in_the_song)\n",
    "audio_arr_exp3, t_predict, t_reconstruct = generation_handler.generate_audio_sample(requested_length, interactive_i=position_in_the_song)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H2iHKgMUmbD"
   },
   "source": [
    "# Play Audio\n",
    "\n",
    "If you want to download the audio, you can use the Colab File Explorer on the left <----. \n",
    "\n",
    "Find the file `generated_output_exp_concat.wav` and select **download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "EKOA8aGg24Zh",
    "outputId": "22fbe8be-01af-4a8e-961a-9872d26722de"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio, Image\n",
    "print(audio_arr_exp1.shape)\n",
    "print(audio_arr_exp2.shape)\n",
    "print(audio_arr_exp3.shape)\n",
    "audio_arr_exp = np.concatenate([audio_arr_exp1,audio_arr_exp2,audio_arr_exp3])\n",
    "\n",
    "out_name = 'generated_output_exp_concat.wav'\n",
    "librosa.output.write_wav(out_name, audio_arr_exp, sr=sample_rate)\n",
    "Audio(out_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieFSgNbIUoPL"
   },
   "source": [
    "# Clean up if you are going to train a new model from a different youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gXtBaGR26oW"
   },
   "outputs": [],
   "source": [
    "# fast cleanup\n",
    "!mkdir unused\n",
    "!mv __music_samples unused/\n",
    "!mv __saved_models unused/\n",
    "!mv *.wav unused/\n",
    "!mv *.m4a unused/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM Audio Generation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
